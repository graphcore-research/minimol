{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found local copy...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 22 - caco2_wang\n",
      "2 / 22 - hia_hou\n",
      "3 / 22 - pgp_broccatelli\n",
      "4 / 22 - bioavailability_ma\n",
      "5 / 22 - lipophilicity_astrazeneca\n",
      "6 / 22 - solubility_aqsoldb\n",
      "7 / 22 - bbb_martins\n",
      "8 / 22 - ppbr_az\n",
      "9 / 22 - vdss_lombardo\n",
      "10 / 22 - cyp2d6_veith\n",
      "11 / 22 - cyp3a4_veith\n",
      "12 / 22 - cyp2c9_veith\n",
      "13 / 22 - cyp2d6_substrate_carbonmangels\n",
      "14 / 22 - cyp3a4_substrate_carbonmangels\n",
      "15 / 22 - cyp2c9_substrate_carbonmangels\n",
      "16 / 22 - half_life_obach\n",
      "17 / 22 - clearance_microsome_az\n",
      "18 / 22 - clearance_hepatocyte_az\n",
      "19 / 22 - herg\n",
      "20 / 22 - ames\n",
      "21 / 22 - dili\n",
      "22 / 22 - ld50_zhu\n",
      "All mols: 53695\n",
      "Unique mols: 35628\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from datamol.mol import standardize_smiles\n",
    "from tdc.benchmark_group import admet_group\n",
    "from contextlib import redirect_stdout, redirect_stderr\n",
    "\n",
    "group = admet_group(path='admet_data/')\n",
    "seed = 42\n",
    "\n",
    "columns = ['smiles']\n",
    "num_mols = 0\n",
    "df = pd.DataFrame(columns=columns)\n",
    "task_types = {}\n",
    "\n",
    "for dataset_i, dataset_name in enumerate(group.dataset_names):\n",
    "    print(f\"{dataset_i + 1} / {len(group.dataset_names)} - {dataset_name}\")\n",
    "    benchmark = group.get(dataset_name)\n",
    "    name = benchmark['name']\n",
    "    task_types[name] = 'classification' if len(benchmark['test']['Y'].unique()) == 2 else 'regression'\n",
    "    \n",
    "    with open(os.devnull, 'w') as fnull, redirect_stdout(fnull), redirect_stderr(fnull): # suppress output\n",
    "        mols_train, mols_valid = group.get_train_valid_split(benchmark=name, split_type='default', seed=seed)\n",
    "\n",
    "    temp_df = pd.DataFrame({\n",
    "        'smiles': mols_train['Drug'],\n",
    "        dataset_name: mols_train['Y']\n",
    "    })\n",
    "\n",
    "    num_mols += len(temp_df)\n",
    "    df = pd.merge(df, temp_df, on='smiles', how='outer')\n",
    "\n",
    "print(f\"All mols: {num_mols}\")\n",
    "print(f\"Unique mols: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from minimol import Minimol\n",
    "\n",
    "featurizer = Minimol()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embeddings'] = featurizer(list(df['smiles']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smiles</th>\n",
       "      <th>caco2_wang</th>\n",
       "      <th>hia_hou</th>\n",
       "      <th>pgp_broccatelli</th>\n",
       "      <th>bioavailability_ma</th>\n",
       "      <th>lipophilicity_astrazeneca</th>\n",
       "      <th>solubility_aqsoldb</th>\n",
       "      <th>bbb_martins</th>\n",
       "      <th>ppbr_az</th>\n",
       "      <th>vdss_lombardo</th>\n",
       "      <th>...</th>\n",
       "      <th>cyp3a4_substrate_carbonmangels</th>\n",
       "      <th>cyp2c9_substrate_carbonmangels</th>\n",
       "      <th>half_life_obach</th>\n",
       "      <th>clearance_microsome_az</th>\n",
       "      <th>clearance_hepatocyte_az</th>\n",
       "      <th>herg</th>\n",
       "      <th>ames</th>\n",
       "      <th>dili</th>\n",
       "      <th>ld50_zhu</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CNC1(c2ccccc2Cl)CCCCC1=O</td>\n",
       "      <td>-4.260000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tensor(1.1916), tensor(0.3334), tensor(0.8102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNC1(c2ccccc2Cl)CCCCC1=O</td>\n",
       "      <td>-4.260000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>42.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tensor(1.1916), tensor(0.3334), tensor(0.8102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C/C=C/C/C=C/CCC(=O)[C@@H]1O[C@@H]1C(N)=O</td>\n",
       "      <td>-5.422406</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tensor(1.2584), tensor(0.7886), tensor(1.3459...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O=C(NC1(C(=O)N[C@H](Cc2ccccc2)C(=O)NCCCC(=O)N2...</td>\n",
       "      <td>-5.769776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tensor(1.8761), tensor(0.1187), tensor(1.0743...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](Cc1ccccc1)NC...</td>\n",
       "      <td>-7.431799</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[tensor(2.0538), tensor(1.9126), tensor(1.1178...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              smiles  caco2_wang  hia_hou  \\\n",
       "0                           CNC1(c2ccccc2Cl)CCCCC1=O   -4.260000      NaN   \n",
       "1                           CNC1(c2ccccc2Cl)CCCCC1=O   -4.260000      NaN   \n",
       "2           C/C=C/C/C=C/CCC(=O)[C@@H]1O[C@@H]1C(N)=O   -5.422406      NaN   \n",
       "3  O=C(NC1(C(=O)N[C@H](Cc2ccccc2)C(=O)NCCCC(=O)N2...   -5.769776      NaN   \n",
       "4  NC(=O)[C@H](Cc1ccccc1)NC(=O)[C@H](Cc1ccccc1)NC...   -7.431799      NaN   \n",
       "\n",
       "   pgp_broccatelli  bioavailability_ma  lipophilicity_astrazeneca  \\\n",
       "0              NaN                 0.0                        NaN   \n",
       "1              NaN                 0.0                        NaN   \n",
       "2              NaN                 NaN                        NaN   \n",
       "3              NaN                 NaN                        NaN   \n",
       "4              NaN                 NaN                        NaN   \n",
       "\n",
       "   solubility_aqsoldb  bbb_martins  ppbr_az  vdss_lombardo  ...  \\\n",
       "0                 NaN          1.0    44.84            NaN  ...   \n",
       "1                 NaN          1.0    42.01            NaN  ...   \n",
       "2                 NaN          NaN      NaN            NaN  ...   \n",
       "3                 NaN          NaN      NaN            NaN  ...   \n",
       "4                 NaN          NaN      NaN            NaN  ...   \n",
       "\n",
       "   cyp3a4_substrate_carbonmangels  cyp2c9_substrate_carbonmangels  \\\n",
       "0                             NaN                             NaN   \n",
       "1                             NaN                             NaN   \n",
       "2                             NaN                             NaN   \n",
       "3                             NaN                             NaN   \n",
       "4                             NaN                             NaN   \n",
       "\n",
       "   half_life_obach  clearance_microsome_az  clearance_hepatocyte_az  herg  \\\n",
       "0              NaN                     NaN                      NaN   NaN   \n",
       "1              NaN                     NaN                      NaN   NaN   \n",
       "2              NaN                     NaN                      NaN   NaN   \n",
       "3              NaN                     NaN                      NaN   NaN   \n",
       "4              NaN                     NaN                      NaN   NaN   \n",
       "\n",
       "   ames  dili  ld50_zhu                                         embeddings  \n",
       "0   NaN   0.0       NaN  [tensor(1.1916), tensor(0.3334), tensor(0.8102...  \n",
       "1   NaN   0.0       NaN  [tensor(1.1916), tensor(0.3334), tensor(0.8102...  \n",
       "2   NaN   NaN       NaN  [tensor(1.2584), tensor(0.7886), tensor(1.3459...  \n",
       "3   NaN   NaN       NaN  [tensor(1.8761), tensor(0.1187), tensor(1.0743...  \n",
       "4   NaN   NaN       NaN  [tensor(2.0538), tensor(1.9126), tensor(1.1178...  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches in the epoch: 557\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class MultiDataset(Dataset):\n",
    "    def __init__(self, samples, tasks):\n",
    "        self.samples = samples['embeddings'].tolist()\n",
    "        self.targets = samples[tasks.keys()].fillna(np.nan).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        target = self.targets[idx]\n",
    "        return sample, target\n",
    "\n",
    "dataloader = DataLoader(MultiDataset(df, task_types), batch_size=64, shuffle=True)\n",
    "print(f\"Number of batches in the epoch: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class ResidualMLP(nn.Module):\n",
    "    def __init__(self, input_size, head_input_size, hidden_size, depth, dropout):\n",
    "        super(ResidualMLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        self.layers.append(nn.Linear(input_size, hidden_size))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        for _ in range(depth - 1):\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.BatchNorm1d(hidden_size))\n",
    "        self.output_layer = nn.Linear(hidden_size, head_input_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        x += identity\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "class TaskHead(nn.Module):\n",
    "    def __init__(self, hidden_size, depth, dropout):\n",
    "        super(TaskHead, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for _ in range(depth):\n",
    "            self.layers.append(nn.Linear(hidden_size, hidden_size))\n",
    "            self.layers.append(nn.LayerNorm(hidden_size))\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(nn.Dropout(dropout))\n",
    "        self.output_layer = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "class MultiTaskModel(nn.Module):\n",
    "    def __init__(self, input_size, trunk_hidden_size, trunk_depth, head_hidden_size, head_depth, dropout, tasks):\n",
    "        super(MultiTaskModel, self).__init__()\n",
    "        self.trunk = ResidualMLP(input_size, head_hidden_size, trunk_hidden_size, trunk_depth, dropout)\n",
    "        self.heads = nn.ModuleDict({task: TaskHead(head_hidden_size, head_depth, dropout) for task in tasks.keys()})\n",
    "        self.tasks = tasks\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        x = self.trunk(x)\n",
    "        outputs = {}\n",
    "        filtered_targets = {}\n",
    "\n",
    "        if targets is None:  # inference\n",
    "            return {task: self.heads[task](x) for task in self.tasks}\n",
    "\n",
    "        task_mask = ~torch.isnan(targets)\n",
    "        for idx, task in enumerate(self.tasks.keys()): \n",
    "            if task_mask[:, idx].any():\n",
    "                indices = np.where(task_mask[:, idx])[0]\n",
    "                outputs[task] = self.heads[task](x[indices]).squeeze()\n",
    "                filtered_targets[task] = targets[indices, idx].squeeze()\n",
    "        return outputs, filtered_targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiTaskModel(\n",
    "    trunk_hidden_size=512,\n",
    "    head_hidden_size=128, \n",
    "    input_size=512, \n",
    "    trunk_depth=2, \n",
    "    head_depth=3, \n",
    "    tasks=task_types, \n",
    "    dropout=0.5 \n",
    ")\n",
    "for batch_idx, (samples, targets) in enumerate(dataloader):\n",
    "    outputs, filtered_targets = model(samples, targets=targets)\n",
    "    for task, output in outputs.items():\n",
    "        if torch.isnan(output).any():\n",
    "            print(task)\n",
    "            print(output)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1 / 10], Train loss: 378.97\n",
      "Epoch [2 / 10], Train loss: 357.80\n",
      "Epoch [3 / 10], Train loss: 281.99\n",
      "Epoch [4 / 10], Train loss: 357.34\n",
      "Epoch [5 / 10], Train loss: 302.66\n",
      "Epoch [6 / 10], Train loss: 278.21\n",
      "Epoch [7 / 10], Train loss: 265.68\n",
      "Epoch [8 / 10], Train loss: 264.86\n",
      "Epoch [9 / 10], Train loss: 309.25\n",
      "Epoch [10 / 10], Train loss: 306.45\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import BCEWithLogitsLoss as bce_loss\n",
    "from torch.nn import MSELoss as mse_loss\n",
    "\n",
    "def compute_loss(outputs, filtered_targets, task_types):\n",
    "    total_loss = torch.tensor(0.0, requires_grad=True)\n",
    "\n",
    "    for task, output in outputs.items():\n",
    "        target = filtered_targets[task].float()\n",
    "\n",
    "        if torch.isnan(output).any(): print(\"NANS IN THE OUTPUT\")\n",
    "        if torch.isnan(target).any(): print(\"NANS IN THE TARGETS\")\n",
    "\n",
    "        if task_types[task] == 'classification':\n",
    "            loss = bce_loss()(output.float(), target.float())\n",
    "        else:  # regression\n",
    "            loss = mse_loss()(output.float(), target.float())\n",
    "\n",
    "        total_loss = total_loss + loss \n",
    "\n",
    "    return total_loss / len(task_types.keys())\n",
    "\n",
    "def train(model, dataloader, task_types, optimizer, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (samples, targets) in enumerate(dataloader):\n",
    "            outputs, filtered_targets = model(samples, targets=targets)\n",
    "            total_loss = compute_loss(outputs, filtered_targets, task_types)\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += total_loss.item()\n",
    "\n",
    "        print(f\"Epoch [{epoch + 1} / {num_epochs}], Train loss: {running_loss / len(dataloader):.2f}\")\n",
    "\n",
    "\n",
    "model = MultiTaskModel(\n",
    "    trunk_hidden_size=512,\n",
    "    head_hidden_size=128, \n",
    "    input_size=512, \n",
    "    trunk_depth=2, \n",
    "    head_depth=3, \n",
    "    tasks=task_types, \n",
    "    dropout=0.5 \n",
    ")\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001, momentum=0.9, weight_decay=0.0001)\n",
    "train(model, dataloader, task_types, optimizer, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".minimol",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
